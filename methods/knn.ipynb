{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb55d32-c8b2-48dc-be67-54e3d29edf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Load the data\n",
    "data = np.loadtxt(('data/preprocessed-dataset.csv'), delimiter=',', skiprows=1)\n",
    "os.chdir(\"methods\")\n",
    "\n",
    "# Split the data into training data and test set\n",
    "x = data[:,1:35]\n",
    "y = data[:,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936da15a-9008-48ee-989e-0f420851d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67dfc3b4-8c7b-4b15-bedd-13078c16b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.83333333 0.82017544 0.77631579 0.77973568 0.84140969 0.78414097\n",
      " 0.79295154 0.76651982 0.76651982 0.84581498]\n",
      "Mean score: 0.8006917072416725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a kNN classifier\n",
    "knn = KNeighborsClassifier(5) # The number of neighbors\n",
    "\n",
    "# Use cross-validation to evaluate the performance of the model\n",
    "scores = cross_val_score(knn, x_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean score:\", scores.mean())\n",
    "\n",
    "# Train the model on the entire training set\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Make predicitons on the test set\n",
    "knn_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957b6d3d-c099-4f12-9314-dbf97d6a981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8101933216168717\n",
      "Precision: 0.7928994082840237\n",
      "Recall: 0.8758169934640523\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def model_info(model_pred):\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, model_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, model_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, model_pred))\n",
    "\n",
    "# Print the performance metrics to the set k-value\n",
    "model_info(knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af3c996-7c0f-4bab-81f2-9edb85857e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better ROC-AUC ( 0.7604438480081512 ) for n =  1\n",
      "Found a better accuracy ( 0.7627416520210897 ) for n =  1\n",
      "Found a better precision ( 0.7731629392971247 ) for n =  1\n",
      "Found a better recall ( 0.7908496732026143 ) for n =  1\n",
      "Found a better precision ( 0.831275720164609 ) for n =  2\n",
      "Found a better ROC-AUC ( 0.8173041079549691 ) for n =  3\n",
      "Found a better accuracy ( 0.820738137082601 ) for n =  3\n",
      "Found a better recall ( 0.8627450980392157 ) for n =  3\n",
      "Found a better precision ( 0.8385964912280702 ) for n =  4\n",
      "Found a better recall ( 0.8758169934640523 ) for n =  5\n",
      "Found a better recall ( 0.8888888888888888 ) for n =  9\n",
      "Found a better recall ( 0.8986928104575164 ) for n =  19\n",
      "Found a better recall ( 0.9084967320261438 ) for n =  21\n",
      "Found a better accuracy ( 0.8224956063268892 ) for n =  31\n",
      "Found a better recall ( 0.9117647058823529 ) for n =  31\n",
      "Found a better recall ( 0.9150326797385621 ) for n =  33\n",
      "Found a better ROC-AUC ( 0.8176333904918114 ) for n =  40\n",
      "Found a better accuracy ( 0.8242530755711776 ) for n =  40\n",
      "Found a better recall ( 0.9183006535947712 ) for n =  57\n",
      "Found a better ROC-AUC ( 0.8184659161509978 ) for n =  59\n",
      "Found a better accuracy ( 0.8260105448154658 ) for n =  59\n",
      "-----------\n",
      "Here are the best values for n: \n",
      "accuracy: 59 \n",
      "precision: 4 \n",
      "recall: 57 \n",
      "ROC-AUC: 59\n"
     ]
    }
   ],
   "source": [
    "# Search for the best k-value for accuracy, precision, recall and AUC-ROC\n",
    "\n",
    "best_acc = 0\n",
    "best_acc_for = 0\n",
    "best_prec = 0\n",
    "best_prec_for = 0\n",
    "best_recall = 0\n",
    "best_recall_for = 0\n",
    "best_roc_auc=0\n",
    "best_roc_auc_for=0\n",
    "\n",
    "for i in range(1,150):\n",
    "    knn = KNeighborsClassifier(i) # Iterating over the number of neighbors\n",
    "    knn.fit(x_train, y_train)\n",
    "    knn_pred = knn.predict(x_test)\n",
    "    if metrics.roc_auc_score(y_test, knn_pred) > best_roc_auc:\n",
    "        best_roc_auc_for = i\n",
    "        best_roc_auc = metrics.roc_auc_score(y_test, knn_pred)\n",
    "        print(\"Found a better ROC-AUC (\", metrics.roc_auc_score(y_test, knn_pred),\") for n = \",best_roc_auc_for)\n",
    "    if metrics.accuracy_score(y_test, knn_pred) > best_acc:\n",
    "        best_acc_for = i\n",
    "        best_acc = metrics.accuracy_score(y_test, knn_pred)\n",
    "        print(\"Found a better accuracy (\", metrics.accuracy_score(y_test, knn_pred),\") for n = \",best_acc_for)\n",
    "    if metrics.precision_score(y_test, knn_pred) > best_prec:\n",
    "        best_prec_for = i\n",
    "        best_prec = metrics.precision_score(y_test, knn_pred)\n",
    "        print(\"Found a better precision (\",metrics.precision_score(y_test, knn_pred),\") for n = \",best_prec_for)\n",
    "    if metrics.recall_score(y_test, knn_pred) > best_recall:\n",
    "        best_recall_for = i\n",
    "        best_recall = metrics.recall_score(y_test, knn_pred)\n",
    "        print(\"Found a better recall (\",metrics.recall_score(y_test, knn_pred),\") for n = \",best_recall_for)\n",
    "        \n",
    "print(\"-----------\\nHere are the best values for n:\",\"\\naccuracy:\",best_acc_for,\"\\nprecision:\",best_prec_for,\"\\nrecall:\",best_recall_for,\"\\nROC-AUC:\",best_roc_auc_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bf9e2-d426-4739-a4af-871fd248c4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "adef9b2e1761d9ef0b2cca68f24c91839ed78d424571b6640ba0ef8dc916354e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
